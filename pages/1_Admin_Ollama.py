import streamlit as st
import subprocess
import psutil
import platform
import shutil
import os

st.set_page_config(page_title="âš™ï¸ Admin Ollama", layout="centered")
st.title("ğŸ› ï¸ Administration des ModÃ¨les Ollama")

# ğŸ“Š VÃ©rifier la RAM disponible
st.subheader("ğŸ“Š Informations systÃ¨me")
ram = psutil.virtual_memory()
st.write(f"ğŸ§  RAM disponible : {round(ram.available / (1024**3), 2)} Go")
st.write(f"ğŸ’½ RAM totale : {round(ram.total / (1024**3), 2)} Go")

# âš ï¸ VÃ©rifier la VRAM GPU (si installÃ©e)
try:
    import torch
    if torch.cuda.is_available():
        gpu = torch.cuda.get_device_name(0)
        vram_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        st.write(f"ğŸ® GPU dÃ©tectÃ© : {gpu}")
        st.write(f"ğŸ–¥ï¸ VRAM disponible : {round(vram_total, 2)} Go")
    else:
        st.info("â— Aucun GPU CUDA dÃ©tectÃ©.")
except:
    st.info("â— PyTorch non installÃ© ou pas de GPU dÃ©tectÃ©.")

# ğŸ”Œ Connexion Ã  Ollama
try:
    import ollama
    models = ollama.list()['models']
    model_names = [m['name'] for m in models]
    st.success("âœ… Ollama dÃ©tectÃ©")
    st.write("ğŸ“¦ ModÃ¨les installÃ©s :", model_names if model_names else "Aucun modÃ¨le")
except Exception as e:
    st.error("âŒ Ollama non dÃ©tectÃ©")
    st.code(str(e))
    st.stop()

# ğŸ¯ Choisir le modÃ¨le par dÃ©faut
st.subheader("ğŸ¯ Choix du modÃ¨le par dÃ©faut")
selected_model = st.selectbox("ModÃ¨le Ã  utiliser dans lâ€™assistant RAG :", model_names)

if st.button("ğŸ’¾ Sauvegarder ce modÃ¨le par dÃ©faut"):
    with open("config_model.txt", "w") as f:
        f.write(selected_model)
    st.success(f"âœ… ModÃ¨le par dÃ©faut enregistrÃ© : {selected_model}")

# ğŸ“¥ TÃ©lÃ©charger un nouveau modÃ¨le
st.subheader("â¬‡ï¸ TÃ©lÃ©charger un nouveau modÃ¨le")
new_model = st.text_input("Nom du modÃ¨le Ã  tÃ©lÃ©charger (ex: tinyllama, mistral, llama2)")

if st.button("ğŸ“¦ TÃ©lÃ©charger"):
    if new_model:
        with st.spinner(f"TÃ©lÃ©chargement de {new_model}..."):
            result = subprocess.run(["ollama", "pull", new_model], capture_output=True, text=True)
            if result.returncode == 0:
                st.success(f"âœ… ModÃ¨le '{new_model}' tÃ©lÃ©chargÃ© avec succÃ¨s.")
                st.code(result.stdout)
            else:
                st.error("âŒ Ã‰chec du tÃ©lÃ©chargement :")
                st.code(result.stderr)
    else:
        st.warning("â›” Veuillez saisir un nom de modÃ¨le.")

# ğŸ—‘ï¸ Supprimer un modÃ¨le
st.subheader("ğŸ—‘ï¸ Supprimer un modÃ¨le installÃ©")
model_to_delete = st.selectbox("SÃ©lectionner un modÃ¨le Ã  supprimer", model_names)

if st.button("âŒ Supprimer le modÃ¨le"):
    with st.spinner(f"Suppression de {model_to_delete}..."):
        result = subprocess.run(["ollama", "rm", model_to_delete], capture_output=True, text=True)
        if result.returncode == 0:
            st.success(f"ğŸ—‘ï¸ ModÃ¨le '{model_to_delete}' supprimÃ© avec succÃ¨s.")
            st.code(result.stdout)
        else:
            st.error("âŒ Ã‰chec de la suppression :")
            st.code(result.stderr)